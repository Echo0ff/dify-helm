# ============================================
# Dify Helm Chart - 生产环境优化配置
# ============================================
# 说明：
# - 本文件包含生产环境的性能优化配置
# - 基于 values-dify.yaml，针对高 RPS 和高可用场景优化
# - 配合 values-secrets.yaml 使用
#
# 集群配置（3节点 HA 集群）: 
#   - Node 1: 32C/128G (high-performance) - 高性能节点，API/Worker 优先调度
#   - Node 2: 16C/32G (standard) - 标准节点，均衡调度
#   - Node 3: 16C/32G (standard) - 标准节点，均衡调度
#
# 优化目标：
#   - 高并发：支持 400+ RPS
#   - 高可用：3 节点 HA，Pod 分散调度
#   - 资源优化：合理的 requests/limits，避免 OOM
#   - 连接池优化：Gunicorn + SQLAlchemy + Redis 连接池调优
#
# 部署命令：
# helm upgrade dify ./charts/dify -n dify \
#   -f values-dify.yaml \
#   -f values-secrets.yaml \
#   -f values-dify-prod.yaml
# ============================================

###################################
# API 服务优化（最关键）
###################################
api:
  enabled: true
  # 初始副本数：6 个（增加API处理能力，主要处理工作流/对话流）
  replicas: 6
  
  # 资源配置：提高单Pod资源，减少超时错误
  resources:
    requests:
      cpu: "2000m"      # 提高到 2 核（确保充足处理能力）
      memory: "4Gi"     # 提高到 4G（避免内存压力）
    limits:
      cpu: "6000m"      # 最多 6 核
      memory: "6Gi"     # 最多 6G（给予充足上限）

  # 自定义 prompts
  persistence:
    enabled: true
    volumes:
      - name: custom-prompts
        configMap:
          name: dify-prompts
    volumeMounts:
      - name: custom-prompts
        mountPath: /app/api/core/llm_generator/prompts.py
        subPath: prompts.py
        readOnly: true
  
  # 启用水平自动伸缩（HPA）- 针对对话流优化
  autoscaling:
    enabled: true
    minReplicas: 6            # 提高最小副本数（优先保证API能力）
    maxReplicas: 12           # 最多 10 个（充分利用集群资源）
    targetCPUUtilizationPercentage: 60    # 60% 扩容（更早响应负载）
    targetMemoryUtilizationPercentage: 65 # 65% 扩容（避免内存瓶颈）
  
  # 优化健康检查 - 更宽容的配置，减少状态错误
  livenessProbe:
    enabled: true
    initialDelaySeconds: 45     # 增加初始延迟，等待应用完全启动
    periodSeconds: 30           # 降低检查频率，减少开销
    timeoutSeconds: 20          # 增加超时时间，避免瞬时高负载误判
    failureThreshold: 12        # 更宽容，12 次失败才重启（减少误杀）
    successThreshold: 1
  
  readinessProbe:
    enabled: true
    initialDelaySeconds: 20     # 增加初始延迟，确保应用准备好
    periodSeconds: 10
    timeoutSeconds: 20          # 增加超时时间
    failureThreshold: 8         # 更宽容，8 次失败才标记不健康（减少状态错误）
    successThreshold: 1         # 1 次成功即可接入流量（加快恢复）
  
  # 滚动更新策略 - 增加 surge 以快速响应流量增长
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 3               # 一次最多增加 3 个 Pod（原 1）
      maxUnavailable: 0         # 确保零停机
  
  # Pod 拓扑分散约束：均匀分布，但允许高性能节点承担更多负载
  topologySpreadConstraints:
    - maxSkew: 2                  # 允许最多 2 个 Pod 的差异（高性能节点可多 2 个）
      topologyKey: kubernetes.io/hostname
      whenUnsatisfiable: ScheduleAnyway  # HA 集群，保证可用性优先
      labelSelector:
        matchLabels:
          component: api
  
  # 亲和性配置：优先利用高性能节点，均衡使用标准节点
  affinity:
    # Pod 反亲和性：适度分散，允许高密度部署
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 20              # 低权重，允许同节点多 Pod（HA 集群更灵活）
          podAffinityTerm:
            labelSelector:
              matchExpressions:
                - key: component
                  operator: In
                  values:
                    - api
            topologyKey: kubernetes.io/hostname
    
    # 节点调度策略：高性能节点优先，标准节点均衡
    nodeAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
        # 最高优先级：高性能节点（32C/120G）
        - weight: 100
          preference:
            matchExpressions:
              - key: node-type
                operator: In
                values:
                  - high-performance
        # 次优先级：标准节点（16C/32G）
        - weight: 50
          preference:
            matchExpressions:
              - key: node-type
                operator: In
                values:
                  - standard
  
  # 保持现有环境变量配置
  logLevel: INFO  # 生产环境建议 INFO，减少日志开销（DEBUG 会影响性能）
  
  extraEnv:
    - name: TZ
      value: "Asia/Shanghai"
    - name: CHECK_UPDATE_URL
      value: ""
    - name: CODE_MAX_NUMBER
      value: "9223372036854775807"
    - name: CODE_MIN_NUMBER
      value: "-9223372036854775808"
    - name: CODE_MAX_DEPTH
      value: "10"
    - name: CODE_MAX_PRECISION
      value: "20"
    - name: CODE_MAX_STRING_LENGTH
      value: "80000"
    - name: CODE_MAX_STRING_ARRAY_LENGTH
      value: "70"
    - name: CODE_MAX_OBJECT_ARRAY_LENGTH
      value: "70"
    - name: CODE_MAX_NUMBER_ARRAY_LENGTH
      value: "1000"
    - name: CODE_EXECUTION_CONNECT_TIMEOUT
      value: "10"
    - name: CODE_EXECUTION_READ_TIMEOUT
      value: "360"
    - name: CODE_EXECUTION_WRITE_TIMEOUT
      value: "10"
    - name: LOG_TZ
      value: "Asia/Shanghai"
    # 优化 Gunicorn 配置（降低 worker 数量，减少数据库连接压力）
    - name: SERVER_WORKER_AMOUNT
      value: "2"                # 每个 Pod 2 个 worker（8 Pod x 2 worker = 16 并发）
    - name: SERVER_WORKER_CLASS
      value: "gevent"           # 使用 gevent 异步 worker 提升并发能力
    - name: SERVER_WORKER_CONNECTIONS
      value: "150"             # 每个 worker 最多 150 个异步连接
    - name: GUNICORN_TIMEOUT
      value: "360"              # 超时 6 分钟（适合长时间运行的工作流）
    # 数据库连接池优化（严格控制总连接数 < 1000，预留 600 个余量）
    # 计算：8-12 Pod，每 Pod 30+15=45 峰值 = 360-540 连接（API）
    - name: SQLALCHEMY_POOL_SIZE
      value: "50"               # 每个 Pod 30 个连接（降低基础连接池，避免耗尽）
    - name: SQLALCHEMY_MAX_OVERFLOW
      value: "25"               # 溢出 15（峰值 45/Pod）
    - name: SQLALCHEMY_POOL_RECYCLE
      value: "300"              # 5分钟回收（避免过早回收导致重连开销）
    - name: SQLALCHEMY_POOL_PRE_PING
      value: "true"             # 连接前检查有效性
    - name: SQLALCHEMY_POOL_TIMEOUT
      value: "120"              # 等待超时 120 秒（给予更多容错时间）
    - name: SQLALCHEMY_ECHO
      value: "false"            # 关闭 SQL 日志
    - name: SQLALCHEMY_ECHO_POOL
      value: "false"            # 关闭连接池日志  
    - name: SQLALCHEMY_POOL_RESET_ON_RETURN
      value: "rollback"         # ⚠️ 核心：归还连接时自动回滚未提交事务
    - name: SQLALCHEMY_POOL_USE_LIFO
      value: "true"             # LIFO模式：优先使用最近的连接，提高缓存命中率
    # Redis 连接池优化（增加连接池避免超时）
    - name: REDIS_POOL_SIZE
      value: "40"               # 每个 Pod 40 个连接（8-12 Pod = 320-480 连接）
    - name: REDIS_POOL_MAX_CONNECTIONS
      value: "60"               # 最大 60 个连接（峰值时使用）
    - name: CELERY_BROKER_POOL_LIMIT
      value: "40"               # Celery broker 连接池（匹配 REDIS_POOL_SIZE）
    # 性能优化配置
    - name: HTTP_REQUEST_MAX_CONNECT_TIMEOUT
      value: "30"               # HTTP 请求连接超时
    - name: HTTP_REQUEST_MAX_READ_TIMEOUT
      value: "60"               # HTTP 请求读取超时
    - name: HTTP_REQUEST_MAX_WRITE_TIMEOUT
      value: "30"               # HTTP 请求写入超时
    - name: RETRY_TIMES
      value: "3"                # 重试次数
    - name: WEB_API_CORS_ALLOW_ORIGINS
      value: "*"                # CORS 配置（如需更严格请调整）
    # 禁用不必要的功能提升性能
    - name: SENTRY_DSN
      value: ""                 # 关闭 Sentry（减少性能开销）
    # 自动删除日志
    # Enable automatic cleanup of workflow run logs to manage database size
    - name: WORKFLOW_LOG_CLEANUP_ENABLED
      value: "true"
    # Number of days to retain workflow run logs (default: 30 days)
    - name: WORKFLOW_LOG_RETENTION_DAYS
      value: "4"
    # Batch size for workflow log cleanup operations (default: 100)
    - name: WORKFLOW_LOG_CLEANUP_BATCH_SIZE
      value: "200"

###################################
# Worker 服务优化（异步任务处理 - 主要处理知识库索引）
###################################
worker:
  enabled: true
  replicas: 3                   # 3 个副本（3节点HA，每节点1个，提高可用性）
  
  resources:
    requests:
      cpu: "1000m"              # 请求 1 核
      memory: "2Gi"             # 请求 2G
    limits:
      cpu: "4000m"              # 最多 4 核（处理密集知识库任务时使用）
      memory: "4Gi"             # 最多 4G
  
  autoscaling:
    enabled: true
    minReplicas: 3              # 最少 3 个（3节点HA，每节点1个）
    maxReplicas: 8              # 最多 8 个（大量知识库索引时扩容）
    targetCPUUtilizationPercentage: 75    # 75% 扩容（避免过早扩容浪费资源）
    targetMemoryUtilizationPercentage: 80 # 80% 扩容
  
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  
  # 拓扑分散约束：均匀分布
  topologySpreadConstraints:
    - maxSkew: 1                  # Worker 保持均匀分布（任务处理需要负载均衡）
      topologyKey: kubernetes.io/hostname
      whenUnsatisfiable: ScheduleAnyway
      labelSelector:
        matchLabels:
          component: worker
  
  affinity:
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 40              # 适度分散
          podAffinityTerm:
            labelSelector:
              matchExpressions:
                - key: component
                  operator: In
                  values:
                    - worker
            topologyKey: kubernetes.io/hostname
    
    # 节点调度策略：优先高性能节点（处理异步任务更快）
    nodeAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 80              # 高性能节点
          preference:
            matchExpressions:
              - key: node-type
                operator: In
                values:
                  - high-performance
        - weight: 50              # 标准节点
          preference:
            matchExpressions:
              - key: node-type
                operator: In
                values:
                  - standard
  
  logLevel: INFO
  
  extraEnv:
    - name: TZ
      value: "Asia/Shanghai"
    - name: LOG_TZ
      value: "Asia/Shanghai"
    # Worker 数据库连接池（3-8 Pod，每 Pod 20+10=30 峰值 = 90-240 连接）
    - name: SQLALCHEMY_POOL_SIZE
      value: "40"
    - name: SQLALCHEMY_MAX_OVERFLOW
      value: "20"
    - name: SQLALCHEMY_POOL_RECYCLE
      value: "300"              # 5分钟回收连接
    - name: SQLALCHEMY_POOL_PRE_PING
      value: "true"
    - name: SQLALCHEMY_POOL_TIMEOUT
      value: "120"
    - name: SQLALCHEMY_POOL_RESET_ON_RETURN
      value: "rollback"         # 归还连接时自动回滚未提交事务
    - name: SQLALCHEMY_POOL_USE_LIFO
      value: "true"             # LIFO模式
    # Celery Worker 优化（使用正确的 Dify 环境变量名）
    - name: CELERY_AUTO_SCALE
      value: "true"             # 启用自动伸缩
    - name: CELERY_MAX_WORKERS
      value: "4"                # 最多 8 个并发 worker
    - name: CELERY_MIN_WORKERS
      value: "2"                # 最少 2 个并发 worker
    - name: CELERY_WORKER_CLASS
      value: "gevent"           # 使用 gevent worker
    - name: MAX_TASK_PRE_CHILD
      value: "100"              # 每个 worker 处理 100 个任务后重启（防止内存泄漏）
    # 自动删除日志
    # Enable automatic cleanup of workflow run logs to manage database size
    - name: WORKFLOW_LOG_CLEANUP_ENABLED
      value: "true"
    # Number of days to retain workflow run logs (default: 30 days)
    - name: WORKFLOW_LOG_RETENTION_DAYS
      value: "7"
    # Batch size for workflow log cleanup operations (default: 100)
    - name: WORKFLOW_LOG_CLEANUP_BATCH_SIZE
      value: "200"
    
    - name: CODE_MAX_NUMBER
      value: "9223372036854775807"
    - name: CODE_MIN_NUMBER
      value: "-9223372036854775808"
    - name: CODE_MAX_DEPTH
      value: "10"
    - name: CODE_MAX_PRECISION
      value: "20"
    - name: CODE_MAX_STRING_LENGTH
      value: "80000"
    - name: CODE_MAX_STRING_ARRAY_LENGTH
      value: "70"
    - name: CODE_MAX_OBJECT_ARRAY_LENGTH
      value: "70"
    - name: CODE_MAX_NUMBER_ARRAY_LENGTH
      value: "1000"
    - name: CODE_EXECUTION_CONNECT_TIMEOUT
      value: "10"
    - name: CODE_EXECUTION_READ_TIMEOUT
      value: "360"
    - name: CODE_EXECUTION_WRITE_TIMEOUT
      value: "10"

###################################
# Beat 服务（定时任务调度器）
###################################
beat:
  enabled: true
  # Beat 只需要 1 个副本（多个会重复执行定时任务）
  
  resources:
    requests:
      cpu: "200m"
      memory: "256Mi"
    limits:
      cpu: "500m"
      memory: "512Mi"
  
  updateStrategy:
    type: Recreate             # Beat 使用 Recreate 策略（避免多实例）
  
  logLevel: INFO
  
  extraEnv:
    - name: TZ
      value: "Asia/Shanghai"
    - name: LOG_TZ
      value: "Asia/Shanghai"
    # Beat 数据库连接池（1 Pod，10+5=15 峰值）
    - name: SQLALCHEMY_POOL_SIZE
      value: "10"
    - name: SQLALCHEMY_MAX_OVERFLOW
      value: "5"
    - name: SQLALCHEMY_POOL_RECYCLE
      value: "300"              # 5分钟回收连接
    - name: SQLALCHEMY_POOL_PRE_PING
      value: "true"
    - name: SQLALCHEMY_POOL_TIMEOUT
      value: "120"
    - name: SQLALCHEMY_POOL_RESET_ON_RETURN
      value: "rollback"
    - name: SQLALCHEMY_POOL_USE_LIFO
      value: "true"
    # 自动删除日志
    # Enable automatic cleanup of workflow run logs to manage database size
    - name: WORKFLOW_LOG_CLEANUP_ENABLED
      value: "true"
    # Number of days to retain workflow run logs (default: 30 days)
    - name: WORKFLOW_LOG_RETENTION_DAYS
      value: "7"
    # Batch size for workflow log cleanup operations (default: 100)
    - name: WORKFLOW_LOG_CLEANUP_BATCH_SIZE
      value: "200"
    - name: CODE_MAX_NUMBER
      value: "9223372036854775807"
    - name: CODE_MIN_NUMBER
      value: "-9223372036854775808"
    - name: CODE_MAX_DEPTH
      value: "10"
    - name: CODE_MAX_PRECISION
      value: "20"
    - name: CODE_MAX_STRING_LENGTH
      value: "80000"
    - name: CODE_MAX_STRING_ARRAY_LENGTH
      value: "70"
    - name: CODE_MAX_OBJECT_ARRAY_LENGTH
      value: "70"
    - name: CODE_MAX_NUMBER_ARRAY_LENGTH
      value: "1000"
    - name: CODE_EXECUTION_CONNECT_TIMEOUT
      value: "10"
    - name: CODE_EXECUTION_READ_TIMEOUT
      value: "360"
    - name: CODE_EXECUTION_WRITE_TIMEOUT
      value: "10"

###################################
# Web 前端服务优化
###################################
web:
  enabled: true
  replicas: 3                   # 3 个副本（3节点HA，每节点1个，提高可用性）
  
  resources:
    requests:
      cpu: "500m"
      memory: "512Mi"
    limits:
      cpu: "1000m"
      memory: "1Gi"
  
  autoscaling:
    enabled: true
    minReplicas: 3              # 最少 3 个（3节点HA，每节点1个）
    maxReplicas: 6              # 最多 6 个（扩容时每节点2个）
    targetCPUUtilizationPercentage: 70
  
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0

  extraEnv:
    - name: TZ
      value: "Asia/Shanghai"
    - name: LOG_TZ
      value: "Asia/Shanghai"
  
  affinity:
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchExpressions:
                - key: component
                  operator: In
                  values:
                    - web
            topologyKey: kubernetes.io/hostname

###################################
# Sandbox 服务优化（代码执行）
###################################
sandbox:
  enabled: true
  replicas: 3                   # 3 个副本（3节点HA，每节点1个，提高可用性）
  
  resources:
    requests:
      cpu: "2000m"
      memory: "2Gi"
    limits:
      cpu: "4000m"
      memory: "4Gi"
  
  autoscaling:
    enabled: true
    minReplicas: 3              # 最少 3 个（3节点HA，每节点1个）
    maxReplicas: 6              # 最多 6 个（扩容时每节点2个）
    targetCPUUtilizationPercentage: 70
  
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  
  affinity:
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchExpressions:
                - key: component
                  operator: In
                  values:
                    - sandbox
            topologyKey: kubernetes.io/hostname
  
  extraEnv:
    - name: TZ
      value: "Asia/Shanghai"
    - name: WORKER_TIMEOUT
      value: "15"
    - name: PIP_MIRROR_URL
      value: "https://mirrors.aliyun.com/pypi/simple/"

###################################
# Proxy 服务优化
###################################
proxy:
  enabled: true
  replicas: 3                   # 3 个副本（3节点HA，每节点1个，提高可用性）
  
  resources:
    requests:
      cpu: "500m"
      memory: "256Mi"
    limits:
      cpu: "1000m"
      memory: "512Mi"
  
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  
  affinity:
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchExpressions:
                - key: component
                  operator: In
                  values:
                    - proxy
            topologyKey: kubernetes.io/hostname
  
  # Nginx 优化配置
  clientMaxBodySize: "100m"     # 增加上传大小限制

  extraEnv:
    - name: TZ
      value: "Asia/Shanghai"
    - name: LOG_TZ
      value: "Asia/Shanghai"

###################################
# SSRF Proxy 服务
###################################
ssrfProxy:
  enabled: true
  replicas: 3                   # 3 个副本（3节点HA，每节点1个，提高可用性）
  
  resources:
    requests:
      cpu: "200m"
      memory: "128Mi"
    limits:
      cpu: "500m"
      memory: "256Mi"
  
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0

  extraEnv:
    - name: TZ
      value: "Asia/Shanghai"
    - name: LOG_TZ
      value: "Asia/Shanghai"

###################################
# Plugin Daemon 服务
###################################
pluginDaemon:
  enabled: true
  replicas: 3                   # 3 个副本（3节点HA，每节点1个，提高可用性）
  
  resources:
    requests:
      cpu: "2000m"
      memory: "4Gi"
    limits:
      cpu: "6000m"
      memory: "8Gi"
  
  # ⚠️ 健康检查配置 - 等待编译完成后再接入流量
  livenessProbe:
    enabled: true
    initialDelaySeconds: 120    # 2分钟后开始存活检查
    periodSeconds: 30
    timeoutSeconds: 10
    failureThreshold: 5
    successThreshold: 1
  
  readinessProbe:
    enabled: true
    initialDelaySeconds: 300    # ⚠️ 5分钟后才标记为就绪（等待编译完成）
    periodSeconds: 10
    timeoutSeconds: 10
    failureThreshold: 3
    successThreshold: 1
  
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  
  affinity:
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchExpressions:
                - key: component
                  operator: In
                  values:
                    - plugin-daemon
            topologyKey: kubernetes.io/hostname
  
  extraEnv:
    - name: TZ
      value: "Asia/Shanghai"
    - name: LOG_TZ
      value: "Asia/Shanghai"
    - name: PIP_MIRROR_URL
      value: "https://mirrors.aliyun.com/pypi/simple/"
    # PluginDaemon 数据库连接池（3 Pod，每 Pod 20+10=30 峰值 = 90 连接）
    - name: SQLALCHEMY_POOL_SIZE
      value: "20"
    - name: SQLALCHEMY_MAX_OVERFLOW
      value: "10"
    - name: SQLALCHEMY_POOL_RECYCLE
      value: "300"              # 5分钟回收连接（与其他服务保持一致）
    - name: SQLALCHEMY_POOL_PRE_PING
      value: "true"
    - name: SQLALCHEMY_POOL_TIMEOUT
      value: "120"              # 增加超时时间
    - name: SQLALCHEMY_POOL_RESET_ON_RETURN
      value: "rollback"
    - name: SQLALCHEMY_POOL_USE_LIFO
      value: "true"
    # 自动删除日志
    # Enable automatic cleanup of workflow run logs to manage database size
    - name: WORKFLOW_LOG_CLEANUP_ENABLED
      value: "true"
    # Number of days to retain workflow run logs (default: 30 days)
    - name: WORKFLOW_LOG_RETENTION_DAYS
      value: "7"
    # Batch size for workflow log cleanup operations (default: 100)
    - name: WORKFLOW_LOG_CLEANUP_BATCH_SIZE
      value: "200"

###################################
# Service 配置
# 注意：Ingress 配置继承自 values-dify.yaml，不在此覆盖
###################################
service:
  type: ClusterIP
  port: 80

###################################
# 全局资源配置
###################################
# 注意：这里的 resources 是示例，实际每个组件已经单独配置
resources: {}

###################################
# 全局节点选择器（如有特殊需求）
###################################
nodeSelector: {}

###################################
# 全局容忍度
###################################
tolerations: []

###################################
# 全局亲和性
###################################
affinity: {}

# ==============================================================================
# 说明：
# 1. API 服务是瓶颈，配置了 8 个基础副本，HPA 8-12 副本自动伸缩
# 2. Worker 配置了 3 个基础副本，HPA 3-8 副本（闲时节省资源给API）
# 3. 其他服务（Web/Sandbox/Proxy等）各 3 个副本（3节点HA，每节点1个）
# 4. 使用 Pod 反亲和性将副本分散到不同节点，保证高可用
# 5. API/Worker 优先调度到高性能节点（32C/120G），其他服务均衡分布
# 6. 生产环境建议监控指标：
#    - API Pod CPU/Memory 使用率（目标 <70%）
#    - HPA 伸缩事件（观察扩缩容频率）
#    - P99 响应时间（目标 <1s）
#    - 错误率（目标 <0.5%）
#    - PostgreSQL 连接数（目标 <1000，保守配置峰值见下）
# 7. 数据库连接数计算（保守配置 - 峰值）：
#    - API: 8-12 Pod × 45 = 360-540 连接
#    - Worker: 3-8 Pod × 60 = 180-480 连接
#    - PluginDaemon: 3 Pod × 30 = 90 连接
#    - Beat: 1 Pod × 15 = 15 连接
#    - 总计峰值：645-1125 连接
#    - 阿里云上限：1600 连接
#    - 安全余量：475-955 连接（30%-60%缓冲）✅ 保守安全
# 8. 并发控制策略（保守配置）：
#    - API 线程数降低到 25（vs 45连接池 = 44%余量）
#    - 单Pod连接池 vs 线程数：45连接 vs 25线程 = 20个缓冲
#    - 确保即使高并发时也不会耗尽连接池
#    - 牺牲部分并发性能换取系统稳定性
# 9. 滚动更新策略：
#    - PluginDaemon: 新Pod等待5分钟后才接入流量（等待编译完成）
#    - API: 新Pod等待20秒后接入流量
#    - maxUnavailable: 0 确保零停机部署
# 
# 使用方式：
# helm upgrade dify charts/dify -f values-dify.yaml -f values-dify-prod.yaml -n dify
# ==============================================================================

